{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b9ae5b9",
   "metadata": {},
   "source": [
    "# Tokenization In NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de1047a0",
   "metadata": {},
   "source": [
    "## Why is Tokenization Important ?\n",
    "\n",
    "**Text Segmentation**: Tokenization divides a continuous stream of text into individual units, making it easier for computers to understand and manipulate. In English and many other languages, words are often separated by spaces, making it natural to tokenize text by splitting at spaces. However, tokenization can also handle languages like Chinese or Thai, which don't use spaces between words, by segmenting text into meaningful chunks based on language-specific rules.\n",
    "\n",
    "\n",
    "**Vocabulary Building**: Tokenization is a crucial step in building the vocabulary of a language model. Each unique token in a corpus contributes to the vocabulary. A larger vocabulary allows a model to represent a wider range of words and concepts.\n",
    "\n",
    "\n",
    "**Text Cleaning**: Tokenization can help in cleaning text by separating punctuation, special characters, and other noise from the main text. This simplifies the subsequent analysis and can lead to more accurate results in tasks like sentiment analysis or text classification.\n",
    "\n",
    "\n",
    "**Feature Extraction**: In NLP, text data is typically converted into numerical vectors for machine learning models to process. Tokenization assigns a unique identifier (e.g., an integer) to each token, enabling the conversion of text into numerical feature vectors. Each token becomes a feature, and its frequency or presence can be used as input for machine learning models.\n",
    "\n",
    "\n",
    "**Text Analysis**: Tokenization is the foundation for various NLP tasks, including:\n",
    "\n",
    "\n",
    "**Text Classification**: Assigning a category or label to a text document based on its tokens.\n",
    "\n",
    "\n",
    "**Named Entity Recognition (NER)**: Identifying and tagging entities (e.g., names of people, places, organizations) in a text.\n",
    "Sentiment Analysis: Analyzing the sentiment (positive, negative, neutral) expressed in a text.\n",
    "\n",
    "\n",
    "**Information Retrieval**: Finding relevant documents or passages in a large corpus based on token matches.\n",
    "Machine Translation: Translating a text from one language to another, often at the token level.\n",
    "\n",
    "\n",
    "**Normalization**: Tokenization can help in normalizing text by converting all characters to lowercase (or uppercase) to ensure consistent processing, and by handling accents, diacritics, or other variations in text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6e9bc2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d916b359",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7.4\n"
     ]
    }
   ],
   "source": [
    "import spacy \n",
    "print(spacy.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24dd4428",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on package spacy:\n",
      "\n",
      "NAME\n",
      "    spacy\n",
      "\n",
      "PACKAGE CONTENTS\n",
      "    __main__\n",
      "    about\n",
      "    attrs\n",
      "    cli (package)\n",
      "    compat\n",
      "    displacy (package)\n",
      "    errors\n",
      "    git_info\n",
      "    glossary\n",
      "    kb (package)\n",
      "    lang (package)\n",
      "    language\n",
      "    lexeme\n",
      "    lookups\n",
      "    matcher (package)\n",
      "    ml (package)\n",
      "    morphology\n",
      "    parts_of_speech\n",
      "    pipe_analysis\n",
      "    pipeline (package)\n",
      "    schemas\n",
      "    scorer\n",
      "    strings\n",
      "    symbols\n",
      "    tests (package)\n",
      "    tokenizer\n",
      "    tokens (package)\n",
      "    training (package)\n",
      "    ty\n",
      "    util\n",
      "    vectors\n",
      "    vocab\n",
      "\n",
      "FUNCTIONS\n",
      "    blank(name: str, *, vocab: Union[spacy.vocab.Vocab, bool] = True, config: Union[Dict[str, Any], confection.Config] = {}, meta: Dict[str, Any] = {}) -> spacy.language.Language\n",
      "        Create a blank nlp object for a given language code.\n",
      "        \n",
      "        name (str): The language code, e.g. \"en\".\n",
      "        vocab (Vocab): A Vocab object. If True, a vocab is created.\n",
      "        config (Dict[str, Any] / Config): Optional config overrides.\n",
      "        meta (Dict[str, Any]): Overrides for nlp.meta.\n",
      "        RETURNS (Language): The nlp object.\n",
      "    \n",
      "    load(name: Union[str, pathlib.Path], *, vocab: Union[spacy.vocab.Vocab, bool] = True, disable: Union[str, Iterable[str]] = [], enable: Union[str, Iterable[str]] = [], exclude: Union[str, Iterable[str]] = [], config: Union[Dict[str, Any], confection.Config] = {}) -> spacy.language.Language\n",
      "        Load a spaCy model from an installed package or a local path.\n",
      "        \n",
      "        name (str): Package name or model path.\n",
      "        vocab (Vocab): A Vocab object. If True, a vocab is created.\n",
      "        disable (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to disable. Disabled\n",
      "            pipes will be loaded but they won't be run unless you explicitly\n",
      "            enable them by calling nlp.enable_pipe.\n",
      "        enable (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to enable. All other\n",
      "            pipes will be disabled (but can be enabled later using nlp.enable_pipe).\n",
      "        exclude (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to exclude. Excluded\n",
      "            components won't be loaded.\n",
      "        config (Dict[str, Any] / Config): Config overrides as nested dict or dict\n",
      "            keyed by section values in dot notation.\n",
      "        RETURNS (Language): The loaded nlp object.\n",
      "\n",
      "DATA\n",
      "    Dict = typing.Dict\n",
      "        A generic version of dict.\n",
      "    \n",
      "    Iterable = typing.Iterable\n",
      "        A generic version of collections.abc.Iterable.\n",
      "    \n",
      "    Union = typing.Union\n",
      "        Union type; Union[X, Y] means either X or Y.\n",
      "        \n",
      "        On Python 3.10 and higher, the | operator\n",
      "        can also be used to denote unions;\n",
      "        X | Y means the same thing to the type checker as Union[X, Y].\n",
      "        \n",
      "        To define a union, use e.g. Union[int, str]. Details:\n",
      "        - The arguments must be types and there must be at least one.\n",
      "        - None as an argument is a special case and is replaced by\n",
      "          type(None).\n",
      "        - Unions of unions are flattened, e.g.::\n",
      "        \n",
      "            assert Union[Union[int, str], float] == Union[int, str, float]\n",
      "        \n",
      "        - Unions of a single argument vanish, e.g.::\n",
      "        \n",
      "            assert Union[int] == int  # The constructor actually returns int\n",
      "        \n",
      "        - Redundant arguments are skipped, e.g.::\n",
      "        \n",
      "            assert Union[int, str, int] == Union[int, str]\n",
      "        \n",
      "        - When comparing unions, the argument order is ignored, e.g.::\n",
      "        \n",
      "            assert Union[int, str] == Union[str, int]\n",
      "        \n",
      "        - You cannot subclass or instantiate a union.\n",
      "        - You can use Optional[X] as a shorthand for Union[X, None].\n",
      "    \n",
      "    logger = <Logger spacy (WARNING)>\n",
      "\n",
      "VERSION\n",
      "    3.7.4\n",
      "\n",
      "FILE\n",
      "    c:\\users\\rizen3\\appdata\\roaming\\python\\python311\\site-packages\\spacy\\__init__.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(spacy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5eb5262",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting en-core-web-sm==3.7.1\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n",
      "                                              0.0/12.8 MB ? eta -:--:--\n",
      "                                              0.1/12.8 MB 4.2 MB/s eta 0:00:04\n",
      "     -                                        0.5/12.8 MB 6.2 MB/s eta 0:00:02\n",
      "     --                                       0.9/12.8 MB 6.8 MB/s eta 0:00:02\n",
      "     ---                                      1.3/12.8 MB 7.3 MB/s eta 0:00:02\n",
      "     -----                                    1.6/12.8 MB 7.3 MB/s eta 0:00:02\n",
      "     ------                                   2.0/12.8 MB 7.6 MB/s eta 0:00:02\n",
      "     -------                                  2.4/12.8 MB 7.8 MB/s eta 0:00:02\n",
      "     --------                                 2.8/12.8 MB 7.9 MB/s eta 0:00:02\n",
      "     ----------                               3.3/12.8 MB 8.1 MB/s eta 0:00:02\n",
      "     -----------                              3.6/12.8 MB 8.0 MB/s eta 0:00:02\n",
      "     ------------                             3.9/12.8 MB 8.1 MB/s eta 0:00:02\n",
      "     -------------                            4.4/12.8 MB 8.0 MB/s eta 0:00:02\n",
      "     --------------                           4.6/12.8 MB 7.8 MB/s eta 0:00:02\n",
      "     ---------------                          4.8/12.8 MB 7.5 MB/s eta 0:00:02\n",
      "     ---------------                          5.1/12.8 MB 7.3 MB/s eta 0:00:02\n",
      "     ----------------                         5.4/12.8 MB 7.3 MB/s eta 0:00:02\n",
      "     -----------------                        5.6/12.8 MB 7.1 MB/s eta 0:00:02\n",
      "     ------------------                       5.8/12.8 MB 7.0 MB/s eta 0:00:02\n",
      "     ------------------                       6.0/12.8 MB 6.9 MB/s eta 0:00:01\n",
      "     -------------------                      6.3/12.8 MB 6.8 MB/s eta 0:00:01\n",
      "     --------------------                     6.7/12.8 MB 6.9 MB/s eta 0:00:01\n",
      "     ---------------------                    7.0/12.8 MB 7.0 MB/s eta 0:00:01\n",
      "     ----------------------                   7.2/12.8 MB 6.9 MB/s eta 0:00:01\n",
      "     -----------------------                  7.5/12.8 MB 6.9 MB/s eta 0:00:01\n",
      "     ------------------------                 7.9/12.8 MB 6.9 MB/s eta 0:00:01\n",
      "     --------------------------               8.3/12.8 MB 7.0 MB/s eta 0:00:01\n",
      "     --------------------------               8.6/12.8 MB 7.0 MB/s eta 0:00:01\n",
      "     ---------------------------              8.9/12.8 MB 6.9 MB/s eta 0:00:01\n",
      "     ----------------------------             9.3/12.8 MB 7.0 MB/s eta 0:00:01\n",
      "     -----------------------------            9.5/12.8 MB 6.9 MB/s eta 0:00:01\n",
      "     ------------------------------           9.8/12.8 MB 6.9 MB/s eta 0:00:01\n",
      "     -------------------------------          10.1/12.8 MB 6.9 MB/s eta 0:00:01\n",
      "     --------------------------------         10.4/12.8 MB 7.0 MB/s eta 0:00:01\n",
      "     ---------------------------------        10.7/12.8 MB 6.9 MB/s eta 0:00:01\n",
      "     ---------------------------------        10.8/12.8 MB 6.7 MB/s eta 0:00:01\n",
      "     ----------------------------------       11.0/12.8 MB 6.6 MB/s eta 0:00:01\n",
      "     -----------------------------------      11.3/12.8 MB 6.6 MB/s eta 0:00:01\n",
      "     -----------------------------------      11.5/12.8 MB 6.5 MB/s eta 0:00:01\n",
      "     -------------------------------------    11.8/12.8 MB 6.5 MB/s eta 0:00:01\n",
      "     --------------------------------------   12.2/12.8 MB 6.5 MB/s eta 0:00:01\n",
      "     --------------------------------------   12.5/12.8 MB 6.4 MB/s eta 0:00:01\n",
      "     ---------------------------------------  12.7/12.8 MB 6.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------  12.8/12.8 MB 6.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------  12.8/12.8 MB 6.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------  12.8/12.8 MB 6.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 12.8/12.8 MB 5.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: spacy<3.8.0,>=3.7.2 in c:\\users\\rizen3\\appdata\\roaming\\python\\python311\\site-packages (from en-core-web-sm==3.7.1) (3.7.4)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\rizen3\\appdata\\roaming\\python\\python311\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\rizen3\\appdata\\roaming\\python\\python311\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\rizen3\\appdata\\roaming\\python\\python311\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\rizen3\\appdata\\roaming\\python\\python311\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\rizen3\\appdata\\roaming\\python\\python311\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in c:\\users\\rizen3\\appdata\\roaming\\python\\python311\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.3)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\rizen3\\appdata\\roaming\\python\\python311\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\rizen3\\appdata\\roaming\\python\\python311\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\rizen3\\appdata\\roaming\\python\\python311\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in c:\\users\\rizen3\\appdata\\roaming\\python\\python311\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.3.4)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in c:\\users\\rizen3\\appdata\\roaming\\python\\python311\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.9.0)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\rizen3\\appdata\\roaming\\python\\python311\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (6.4.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\rizen3\\appdata\\roaming\\python\\python311\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.66.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\rizen3\\appdata\\roaming\\python\\python311\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.31.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\rizen3\\appdata\\roaming\\python\\python311\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.10.12)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\rizen3\\appdata\\roaming\\python\\python311\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.2)\n",
      "Requirement already satisfied: setuptools in c:\\program files\\python311\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (65.5.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\rizen3\\appdata\\roaming\\python\\python311\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (23.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\rizen3\\appdata\\roaming\\python\\python311\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.3.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\rizen3\\appdata\\roaming\\python\\python311\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.24.3)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\rizen3\\appdata\\roaming\\python\\python311\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\rizen3\\appdata\\roaming\\python\\python311\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\rizen3\\appdata\\roaming\\python\\python311\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\rizen3\\appdata\\roaming\\python\\python311\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\rizen3\\appdata\\roaming\\python\\python311\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2023.5.7)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\rizen3\\appdata\\roaming\\python\\python311\\site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\rizen3\\appdata\\roaming\\python\\python311\\site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\rizen3\\appdata\\roaming\\python\\python311\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\rizen3\\appdata\\roaming\\python\\python311\\site-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.1.3)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in c:\\users\\rizen3\\appdata\\roaming\\python\\python311\\site-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\rizen3\\appdata\\roaming\\python\\python311\\site-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.1.5)\n",
      "\u001b[38;5;2m[+] Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# !pip install --upgrade click spacy\n",
    "\n",
    "!python -m spacy download en_core_web_sm \n",
    "# Need to download all the times (auto deletes after runtime expires.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26847892",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "My\n",
      "Name\n",
      "is\n",
      "Bond\n",
      ",\n",
      "James\n",
      "Bond\n",
      ".\n",
      "I\n",
      "love\n",
      "panipuri\n",
      "<class 'spacy.tokens.doc.Doc'>\n"
     ]
    }
   ],
   "source": [
    "text = \"My Name is Bond, James Bond. I love panipuri\"\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "doc = nlp(text)\n",
    "\n",
    "print(doc.__len__()) # Count of tokens in doc.\n",
    "\n",
    "for token in doc:\n",
    "    print(token.text)\n",
    "    \n",
    "print(type(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9656bd6c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My Name is Bond, James Bond.\n",
      "I love panipuri\n"
     ]
    }
   ],
   "source": [
    "for sentence in doc.sents: # Printing as sentences.\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32330d88",
   "metadata": {},
   "source": [
    "# Stemming & Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f06cb43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2bed3870",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e4b4661b-c5b9-4ec4-95c9-a8f7efde666b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eating | eat\n",
      "ability | abil\n",
      "ate | ate\n",
      "rafting | raft\n",
      "agility | agil\n",
      "meeting | meet\n"
     ]
    }
   ],
   "source": [
    "words = [\"eating\",\"ability\",\"ate\",\"rafting\",\"agility\",\"meeting\"]\n",
    "for word in words:\n",
    "    print(word ,\"|\",stemmer.stem(word))\n",
    "\n",
    "# Stemmer can't stem complex words like ability,ate, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d8a8cfbd-7a20-4215-9add-f326a7f04d6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eating | eat | 9837207709914848172\n",
      "eats | eat | 9837207709914848172\n",
      "ability | ability | 11565809527369121409\n",
      "ate | eat | 9837207709914848172\n",
      "rafting | raft | 7154368781129989833\n",
      "agility | agility | 4291486835428689731\n",
      "meeting | meeting | 14798207169164081740\n",
      "better | well | 4525988469032889948\n"
     ]
    }
   ],
   "source": [
    "new_doc = nlp(\"eating eats ability ate rafting agility meeting better\")\n",
    "for token in  new_doc:\n",
    "    print(token,\"|\",token.lemma_,\"|\",token.lemma)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "619f269f-3d71-41ec-840a-7e513d861bac",
   "metadata": {},
   "source": [
    "### Stemming : Stems/Clips the word free from -ing forms or suffixes.\n",
    "    \n",
    "    \n",
    "    Ex : eating -> eat, swimming -> swimm\n",
    "\n",
    "### Lemmatization :Using Rules of Language  to remove suffixes or simplify words in their root form.\n",
    "    \n",
    "    \n",
    "    Ex: better -> good/well, ate -> eat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62219fa6-97f3-4944-ab52-c3de59c73c37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fbb270e-1562-46cb-b760-582acc5e46ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c9a18e-daff-4b59-8e0f-1c42f53c6087",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58f693f-c417-46da-b1ba-de8f1dc46053",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
